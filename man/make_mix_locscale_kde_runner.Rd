% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/runner_mix_locscale_kde.R
\name{make_mix_locscale_kde_runner}
\alias{make_mix_locscale_kde_runner}
\title{Create a mixture-of-experts location-scale residual KDE runner for direct conditional density estimation}
\usage{
make_mix_locscale_kde_runner(
  rhs_list,
  K_grid = c(1L, 2L, 3L),
  gate_grid = c("const", "glm"),
  var_grid = c("by_component", "shared"),
  kde_bw_method_grid = c("nrd0", "SJ"),
  kde_adjust_grid = c(1, 1.3),
  init_grid = c("kmeansA", "random"),
  max_iter = 200L,
  tol = 1e-06,
  eps = 1e-15,
  min_sigma = 1e-06,
  min_pi = 1e-10,
  kde_n = 1024L,
  kde_trim = 5,
  strip_fit = TRUE,
  seed = NULL
)
}
\arguments{
\item{rhs_list}{A list of RHS specifications, either as one-sided formulas
(for example, \code{~ x1 + x2}) or as character strings
(for example, \code{"x1 + x2"}). These RHS are used to build the design
matrix for both expert mean models \eqn{\mu_k(W)} and, when \code{gate_grid}
includes \code{"glm"}, the gating model for \eqn{\pi_k(W)}.}

\item{K_grid}{Integer vector of candidate mixture sizes \eqn{K}.}

\item{gate_grid}{Character vector specifying gating model choices for
\eqn{\pi_k(W)}. Supported values are \code{"const"} and \code{"glm"}.}

\item{var_grid}{Character vector specifying the scale structure.
Supported values are \code{"shared"} (one common \eqn{\sigma} across components)
and \code{"by_component"} (component-specific \eqn{\sigma_k}).}

\item{kde_bw_method_grid}{Character vector of KDE bandwidth rules. Supported
values are \code{"nrd0"} and \code{"SJ"}. These bandwidth rules are applied
to standardized residuals within each component.}

\item{kde_adjust_grid}{Numeric vector of multiplicative bandwidth adjustments.}

\item{init_grid}{Character vector specifying initialization strategies for
responsibilities. Supported values are \code{"kmeansA"} (k-means on \eqn{A})
and \code{"random"} (random component assignment).}

\item{max_iter}{Integer maximum number of EM iterations for each tuning row.}

\item{tol}{Nonnegative convergence tolerance for relative change in the
observed-data log-likelihood.}

\item{eps}{Small positive constant used to bound residual KDE densities away
from zero and log-densities away from \eqn{-\infty}.}

\item{min_sigma}{Small positive constant used as a floor for the estimated
scale parameter(s) \eqn{\sigma} or \eqn{\sigma_k}.}

\item{min_pi}{Small positive constant used as a floor for mixture weights
\eqn{\pi_k(W)} prior to renormalization.}

\item{kde_n}{Integer number of grid points used in \code{stats::density()}
for each component KDE.}

\item{kde_trim}{Nonnegative scalar controlling the residual-domain padding
used when forming the KDE evaluation grid. The grid endpoints are set using
high and low residual quantiles plus \code{kde_trim} times the residual
standard deviation.}

\item{strip_fit}{Logical. If TRUE (default), store lightweight
coefficient-based representations sufficient for prediction and sampling.
If FALSE, store the full internal fit objects produced during EM.}

\item{seed}{Optional integer seed. If provided, each tuning row is fit with
a deterministic seed offset (for example, \code{seed + .tune}) to improve
reproducibility.}
}
\value{
A named list (runner) with elements:
  method: Character string \code{"mix_locscale_kde"}.
  tune_grid: Data frame describing the tuning grid, including \code{.tune}.
  fit: Function \code{fit(train_set, ...)} returning a fit bundle.
  log_density: Function \code{log_density(fit_bundle, newdata, ...)} returning
    an \eqn{n \times K} matrix of log-densities.
  fit_one: Function \code{fit_one(train_set, tune, ...)} fitting only the
    selected tuning index.
  sample: Function \code{sample(fit_bundle, newdata, n_samp, ...)} drawing
    samples (assumes \eqn{K = 1}).

Data requirements

The runner expects \code{train_set} and \code{newdata} in wide format containing:
\itemize{
\item a numeric outcome column \code{A} (required for \code{fit()} and \code{log_density()}),
\item covariates referenced in \code{rhs_list}.
}
\code{sample()} expects \code{newdata} to contain only covariates \code{W}
(it must not require an \code{A} column).
}
\description{
Constructs a runner (learner adapter) compatible with the
dsldensify() / run_direct_setting() / summarize_and_select() workflow for
direct conditional density estimation of a continuous outcome \eqn{A} given
covariates \eqn{W}.
}
\details{
This runner models the conditional density as a finite mixture of
location-scale residual density components ("experts"):
\deqn{f(a \mid W) = \sum_{k=1}^K \pi_k(W)\, f_k(a \mid W),}
where mixture weights \eqn{\pi_k(W)} satisfy \eqn{\pi_k(W) \ge 0} and
\eqn{\sum_{k=1}^K \pi_k(W) = 1}.

Each expert \eqn{f_k(a \mid W)} uses a location-scale decomposition with a
nonparametric residual density on the standardized residual scale:
\deqn{A = \mu_k(W) + \sigma_k(W)\,\varepsilon_k,}
\deqn{f_k(a \mid W) = g_k\!\left(\frac{a - \mu_k(W)}{\sigma_k(W)}\right)\,\frac{1}{\sigma_k(W)},}
where \eqn{\mu_k(W)} is a component-specific mean function, \eqn{\sigma_k(W) > 0}
is a component-specific (or shared) scale parameter, and \eqn{g_k} is a
univariate residual density estimated by kernel density estimation (KDE)
on standardized residuals.

Mixture weights (gating)

The mixture weights \eqn{\pi_k(W)} are controlled by \code{gate_grid}:
\itemize{
\item \code{"const"}: constant mixing proportions, \eqn{\pi_k(W) = \pi_k}.
\item \code{"glm"}: multinomial logistic gating on the design matrix built
  from \code{rhs_list}, using a baseline-category parameterization and
  softmax normalization.
}

Estimation by EM

For each tuning configuration, the runner fits the mixture using an
expectation-maximization (EM) algorithm on the observed-data log-likelihood.
Let \eqn{r_{ik}} denote the responsibility of component \eqn{k} for observation
\eqn{i}. The EM iterations proceed as follows:

E-step:
\deqn{r_{ik} \propto \pi_k(W_i)\, g_k\!\left(\frac{A_i - \mu_k(W_i)}{\sigma_k}\right)\,\frac{1}{\sigma_k},}
where the proportionality constant is chosen so that \eqn{\sum_{k=1}^K r_{ik} = 1}.

M-step:
\enumerate{
\item Update component mean functions \eqn{\mu_k(W)} by weighted least squares
  regression of \eqn{A} on the design matrix induced by \code{rhs_list},
  using weights \eqn{r_{ik}}.
\item Update component scales \eqn{\sigma_k} according to \code{var_grid}:
  either a common shared scale across components (\code{"shared"}) or
  component-specific scales (\code{"by_component"}). Predicted scales are
  floored by \code{min_sigma} for numerical stability.
\item Update component residual KDEs \eqn{g_k} by fitting a univariate KDE on
  standardized residuals \eqn{\hat\varepsilon_{ik} = (A_i - \hat\mu_k(W_i))/\hat\sigma_k}
  using weights \eqn{r_{ik}}.
\item Update mixture weights \eqn{\pi_k(W)} using either constant proportions
  (weighted averages of responsibilities) or multinomial logistic gating
  on the design matrix built from \code{rhs_list}.
}

Convergence is assessed using the relative change in the observed-data log-likelihood,
stopping when the criterion falls below \code{tol} or after \code{max_iter} iterations.

Kernel density estimation on residuals

For each component \eqn{k}, the residual density \eqn{g_k} is estimated by
\code{stats::density()} on standardized residuals. The KDE bandwidth rule is
controlled by \code{kde_bw_method_grid} and multiplicative scaling by
\code{kde_adjust_grid}. The estimated density is stored as a linear interpolant
via \code{approxfun()} for evaluation, and an inverse-CDF interpolant is stored
for sampling. The inverse-CDF interpolant is built from the numerically
integrated KDE CDF on the residual grid.

Model selection via log_density()

Model selection uses likelihood-based scoring via log_density(): for each
tuning row and each observation, log_density() evaluates
\deqn{\log \hat f(A_i \mid W_i),}
where \eqn{\hat f} is the fitted mixture-of-experts KDE density described above.
During cross-validation, \code{log_density()} returns an \eqn{n \times K}
matrix of log-densities aligned to \code{tune_grid$.tune}, where
\eqn{K = nrow(tune_grid)}.

Sampling from the fitted model

The runner provides a \code{sample()} method that generates draws
\deqn{A^\ast \sim \hat f(\cdot \mid W)}
by first sampling a component label \eqn{Z \in \{1,\dots,K\}} from
\eqn{\hat\pi(W)} and then sampling \eqn{\varepsilon^\ast} from the corresponding
residual KDE via inverse-CDF sampling. The final draw is formed as
\deqn{A^\ast = \hat\mu_Z(W) + \hat\sigma_Z\,\varepsilon^\ast.}
Sampling assumes the fit bundle contains exactly one tuned fit
(length(fit_bundle$fits) == 1), which is the intended post-selection usage.

Numeric-only requirement

This runner is intended for use with numeric predictors only. All variables
referenced in \code{rhs_list} must be numeric. Factor handling is not
supported and variables are not coerced internally.

Tuning grid

The tuning grid is the Cartesian product of:
\itemize{
\item RHS specifications from \code{rhs_list},
\item mixture size \code{K_grid},
\item gating model choice \code{gate_grid},
\item variance structure \code{var_grid},
\item KDE bandwidth rule \code{kde_bw_method_grid} and adjustment \code{kde_adjust_grid},
\item initialization strategy \code{init_grid}.
}

Stabilization and numerical safety

Densities on the residual scale are bounded below by \code{eps} before taking logs.
Mixture weights are bounded below by \code{min_pi} and renormalized to sum to one.
Scale parameters are bounded below by \code{min_sigma}. These stabilizations are
applied both during EM updates and during prediction.
}
\examples{
runner <- make_mix_locscale_kde_runner(
  rhs_list = list(~ x1 + x2),
  K_grid = c(1L, 2L),
  gate_grid = c("const", "glm"),
  var_grid = c("shared"),
  kde_bw_method_grid = c("nrd0"),
  kde_adjust_grid = c(1.0),
  init_grid = c("kmeansA"),
  strip_fit = TRUE,
  eps = 1e-10,
  seed = 123
)

}
